---
title: "ST443 Group Project - Task 2"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

# ST443 Group Project

# Task 2: Feature selection

# Introduction

The aim of task 2 is to select properties of a molecule in a compound or random probe determine whether a compound binds to a target site on thrombin. This knowledge is required to design new compounds that can be used in drugs.

# T1.1 Data Exploration, Summary Statistics and Visualisation

```{r}
# Loading all libraries required to execute the code in this notebook
library(ggplot2)
library(dplyr)
library(caret)
library(glmnet)
library(pROC)
library(yardstick)
library(Rtsne)
library(randomForest)
library(xgboost)
library(doParallel)
library(e1071)
library(gbm)         
```

```{r}
# Loading and viewing the data
MLData_Task2 <- read.csv("data2.csv.gz", header=TRUE)
View(MLData_Task2)
```

```{r}
# Checking for any missing values in the dataset
any(is.na(MLData_Task2))
```

## Illustration of data with tsne

tSNE (t-distributed Stochastic Neighbor Embedding) is a non-linear dimensionality reduction technique that transforms high-dimensional datasets of points to a low-dimensional representation while preserving as much of the significant structure of the high-dimensional data as possible. We will use this technique to visualize and understand patterns in the data.

```{r}
# Create separate feature matrix and vector with label values
labels <- MLData_Task2$label
data_matrix <- MLData_Task2[, -1]  

# Identify and remove zero-variance columns
non_constant_cols <- apply(data_matrix, 2, var) > 0
data_matrix_clean <- as.matrix(data_matrix[, non_constant_cols])

# Set seed to deal wit randomness of tSNE and ensure consistent results
set.seed(123)

# Perform t-SNE on the dataset
tsne_results <- Rtsne(as.matrix(data_matrix_clean), dims = 2, perplexity = 30, verbose = FALSE)

# Prepare data for visualization
tsne_data <- as.data.frame(tsne_results$Y)
tsne_data$label <- labels

# Extract the embedding from t-SNE results
tsne_data <- as.data.frame(tsne_results$Y)

# Add column names for visualisation on axes in plot
colnames(tsne_data) <- c("Dimension1", "Dimension2")

# Add labels
tsne_data$label <- labels  
```

```{r}
# Plot tSNE
ggplot(tsne_data, aes(x = Dimension1, y = Dimension2, color = as.factor(label))) +
  geom_point(size = 2, alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "t-SNE Visualization",
    x = "Dimension 1",
    y = "Dimension 2",
    color = "Label"
  ) +
  theme(plot.title = element_text(hjust = 0.5))
```

## Dataset-level statistics

```{r}
# Calculate the Feature-Row ratio
cat("Number of features:", ncol(MLData_Task2), "\n")
cat("Number of samples:", nrow(MLData_Task2), "\n")
cat("Feature-to-sample ratio:", ncol(MLData_Task2) / nrow(MLData_Task2), "\n")
```

As we can see, we are clearly dealing with high-dimensional data, meaning that p \>\> n.

```{r}
# Calculate the overall sparsity of the dataset (proportion of zeros in the dataset)
sum(MLData_Task2 == 0) / (nrow(MLData_Task2) * ncol(MLData_Task2))
```

```{r}
# Subset dataset to  800 rows and 2000 columns for visualisation purposes
subset_data <- MLData_Task2[1:800, 2:2001]

# Convert to dataframe
subset_df <- as.data.frame(as.table(as.matrix(subset_data)))
colnames(subset_df) <- c("Row", "Column", "Value")

# Plot the sparse matrix
ggplot(subset_df, aes(x = Column, y = Row, fill = as.factor(Value))) +
  geom_raster() +
  scale_fill_manual(values = c("white", "black")) +
  theme_minimal() +
  labs(
    title = "Sparse Matrix Visualization",
    x = "Columns",
    y = "Rows",
    fill = "Value"
  )+
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks = element_blank()
  )
```

The calculation and the plot shows that our dataset is extremly sparse, i.e. it contains a significant number of zero values relative to its size.

```{r}
# Check if the dataset is balanced, i.e. if the frequency of each class is approx. the same
table(MLData_Task2$label)
```

The table shows that our data is heavily imbalanced - it contains much more observations of class -1 than of class 1. We will take this into account when training our models later.

```{r}
# Plot Class Distribution
ggplot(MLData_Task2, aes(x = as.factor(label), fill = as.factor(label))) +
  geom_bar(alpha = 0.7, color = "black") +
  scale_fill_manual(values = c("red", "blue"), labels = c("Label -1", "Label 1")) +
  labs(
    title = "Class Distribution",
    x = "Class Label",
    y = "Count",
    fill = "Class"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )
```

The plot visualizes the class imbalance.

## Feature-level Statistics

```{r}
# Calculate the variance of each feature and check the proportion of low-variance
feature_variances <- apply(MLData_Task2, 2, var)
cat("Proportion of low-variance features (< 0.01):", mean(feature_variances < 0.01), "\n")
```

As we can see, approximately 69% of the features in our dataset have a variance below 0.01. In the upcoming chapters, we will consider the limitations of low-variance features, as they typically provide minimal variability across data points and are less likely to correlate meaningfully with the target variable. Additionally, such features often introduce more noise than signal, reducing their predictive value. To reduce computational complexity and ensure efficient model training on our available hardware, we will apply a variance threshold for some models, selecting only features with variance above a certain level.

```{r}
# Plot histogram of feature variance
hist(feature_variances, xlim = c(0,0.2), breaks = 100, xlab = "Feature variances", main = "Frequency of feature variances", col="green", plot =TRUE)
```

The histogram visualises that there is a large amount of features with a variance around 0, and only comparably few with a larger variance.

# T2.2 Training and Evaluation of Feature Selection methods

For all our models, we will be using an 80/20 Train to Test data split. We will run a cross-validation on the train set to select the best parameter values for our models. Then we will fit our model with the selected parameter values on the test data to see how well it performs on unseen data. The metric of evaluation in all cases is the balanced accuracy. Since balanced accuracy is not available as a pre-defined metric in the R methods we are using, we have implemented a custom function to calculate it.

## Generalized Linear Model with LASSO

We chose Lasso with linear regression and subsequent conversion at a threshold for classification as our first model. As it's a regularization method that adds a penalty to the model's coefficients and shrinking less important ones to zero, it effectively performs feature selection.

At first we create the training and testing set.

```{r}
# Random split (80% training, 20% testing)
set.seed(123)
train_indices <- sample(1:nrow(MLData_Task2), size = 0.8 * nrow(MLData_Task2))
```

```{r}
# Create training and testing datasets
train2_data <- MLData_Task2[train_indices, ]
test2_data <- MLData_Task2[-train_indices, ]

# Prepare data to be suitable for lasso model
train_X <- as.matrix(train2_data[, -1])
test_X <- as.matrix(test2_data[, -1])
train_Y <- factor(train2_data$label, levels = c(-1, 1), labels = c(0, 1))
test_Y <- factor(test2_data$label, levels = c(-1, 1), labels = c(0, 1))

# Verify split
cat("Training set size:", nrow(train2_data), "\n")
cat("Test set size:", nrow(test2_data), "\n")
```

We are dealing with an extremely high-dimensional dataset and when trying to run the model on all 100,000 features we encountered a convergence issue. Thus, we will perform a feature-pre-selection based on the variance of the features to reduce computational complexity and ensure convergence. We will drop all features with a variance below 0.01 as they will likely not serve as good predictors.

```{r}
# Calculate the variance of each feature
feature_variances <- apply(train_X, 2, var)

# Identify features with variance >= 0.01
selected_features <- which(feature_variances >= 0.01)

# Print the number of features removed
cat("Number of features removed:", ncol(train_X) - length(selected_features), "\n")
cat("Number of features retained:", length(selected_features), "\n")

# Apply on training and test dataset
train_X <- train_X[, selected_features]
test_X <- test_X[, selected_features]
```

The performance metric that we are trying to optimize is the balanced accuracy. To be able to access this metric in our cross-validation when trying to find the best shrinkage parameter lambda, we store the balanced accuracy as a function.

```{r}
# Define custom balanced accuracy function
calculate_balanced_accuracy <- function(data, lev = NULL, model = NULL) {
  confusion_matrix <- table(data$obs, data$pred)
  
  if (nrow(confusion_matrix) < 2 || ncol(confusion_matrix) < 2) {
    sensitivity <- 0
    specificity <- 0
  } else {
    TP <- confusion_matrix[2, 2]
    FN <- confusion_matrix[2, 1]
    TN <- confusion_matrix[1, 1]
    FP <- confusion_matrix[1, 2]
    sensitivity <- TP / (TP + FN)
    specificity <- TN / (TN + FP)  
  }
  
  balanced_acc <- (sensitivity + specificity) / 2
  return(c(BalancedAccuracy = balanced_acc))
}
```

Because of the high imbalance in classes in our dataset, we will assign weights according to the share of the different classes in the dataset and pass these to our model.

```{r}
# Assign weights to classes
class_weights <- ifelse(train2_data$label == 1, nrow(train2_data)/ (2*sum(train2_data$label==1)), nrow(train2_data)/ (2*sum(train2_data$label==-1)))
```

We will perform a 4-fold cross validation on the data using the train control function and balanced accuracy as the metric for evaluation to find the best value for the penalty coefficient lambda.

```{r}
# Define train control with custom function for balanced accuracy
train_control <- trainControl(
  method = "cv",
  number = 4,
  summaryFunction = calculate_balanced_accuracy,
  classProbs = TRUE,
  savePredictions = "final"
)
```

Playing around with different values of lambda showed us, that the optimal value for lambda should lie between 0.00001 and 0.3. Therefore we will define a grid in that range.

```{r}
# Define grid for lambda values
lambda_grid <- expand.grid(
  alpha = 1,
  lambda = 10^seq(-5, -0.5, length.out = 100)
)
```

We will now train our model on the training set and extract the best value for lambda as well as the number of non-zero coefficients, which is equivalent to the number of features that the final Lasso model selects.

```{r}
# Convert label column to factor
train_Y <- factor(train_Y, levels = c(0, 1), labels = c("Class0", "Class1"))
test_Y <- factor(test_Y, levels = c(0, 1), labels = c("Class0", "Class1"))

# Set seed for reproducibility and comparison with other models
set.seed(123)
# Train Lasso model with goal to optimize balanced accuracy
lasso_model <- train(
  x = train_X,
  y = train_Y,
  method = "glmnet",
  trControl = train_control,
  tuneGrid = lambda_grid,
  metric = "BalancedAccuracy",
  weights = class_weights
)

# Print the best lambda
best_lambda <- lasso_model$bestTune$lambda
print(lasso_model$bestTune)

# Extract coefficients for the best lambda
coefficients <- coef(lasso_model$finalModel, s = best_lambda)

# Count non-zero coefficients (excluding the intercept)
non_zero_count <- sum(coefficients != 0) - 1
cat("Number of non-zero coefficients:", non_zero_count, "\n")
```

The best value for lambda according to our cross-validation is \~ 0.059, so this is the value we will use to evaluate our model on the test data. Also, we can see that the number of features selected in our best model is 42. In the following plot we can see how the balanced accuracy differs with respect to the number of features that was chosen.

```{r}
# Extract results from the trained model
results <- lasso_model$results

# Extract balanced accuracy and lambda values
balanced_accuracies <- results$BalancedAccuracy
lambda_values <- results$lambda

# Calculate the number of selected features for each lambda
num_features <- sapply(lambda_values, function(lambda) {
  coefficients <- coef(lasso_model$finalModel, s = lambda)
  sum(coefficients != 0) - 1
})

# Plot Balanced Accuracy vs. Number of Selected Features
plot(
  num_features, balanced_accuracies, type = "b",
  xlab = "Number of Selected Features", ylab = "Balanced Accuracy",
  main = "Balanced Accuracy vs. Number of Selected Features",
  pch = 16,
  cex = 0.5,
  col = "blue",
  lwd = 1.0
)
```

In this final part, we evaluate how well our chosen model performs on the unseen test data. The metric of evaluation is still the balanced accuracy.

```{r}
# Predict probabilities on the test data
lasso_probs <- predict(lasso_model, newdata = test_X, type = "prob")

# Convert probabilities to class predictions using a threshold (e.g., 0.5)
lasso_preds <- ifelse(lasso_probs[, "Class1"] > 0.5, "Class1", "Class0")

# Ensure predictions are factors with the same levels as test_Y
lasso_preds <- factor(lasso_preds, levels = levels(test_Y))

# Calculate balanced accuracy
confusion_matrix <- table(test_Y, lasso_preds)
sensitivity <- confusion_matrix[2, 2] / (confusion_matrix[2, 2] + confusion_matrix[2, 1])
specificity <- confusion_matrix[1, 1] / (confusion_matrix[1, 1] + confusion_matrix[1, 2])

balanced_accuracy <- (sensitivity + specificity) / 2
cat("Balanced Accuracy on Test Data:", balanced_accuracy, "\n")
```

We get a final balanced accuracy on the test data of \~ 0.77 for the lasso model.

## Random Forest for Feature Selection

We chose Random Forest as the next model for feature selection. We believe that as it builds multiple decision trees and aggregates their results to improve predictive performance while ranking feature importance, it is a robust choice.

At first we create the training and testing set.

```{r}
# Set seed for reproducibility and comparison with other models
set.seed(123)

# Random split (80% training, 20% testing)
train_indices <- sample(1:nrow(MLData_Task2), size = 0.8 * nrow(MLData_Task2))

# Create training and testing datasets
train2_data <- MLData_Task2[train_indices, ]
test2_data <- MLData_Task2[-train_indices, ]

# Prepare data
train_X <- as.matrix(train2_data[, -1])
test_X <- as.matrix(test2_data[, -1])
train_Y <- factor(train2_data$label, levels = c(-1, 1), labels = c(0, 1))
test_Y <- factor(test2_data$label, levels = c(-1, 1), labels = c(0, 1))

# Verify split
cat("Training set size:", nrow(train2_data), "\n")
cat("Test set size:", nrow(test2_data), "\n")
```

For a random forest of classification trees, we usually use a random selection of m= sqrt(p) predictors as split candidates each time a split in a tree is considered. However in our case this would mean m = sqrt(100,000) = \~316, which is extremely computationally expensive. Thus we will again apply a pre-selection of features by removing those features with a variance below 0.01 - given the low variance, these features will likely not serve as good predictors for our classification task.

```{r}
# Calculate the variance of each feature
feature_variances <- apply(train_X, 2, var)

# Identify features with variance >= 0.01
selected_features <- which(feature_variances >= 0.01)

# Print the number of features removed
cat("Number of features removed:", ncol(train_X) - length(selected_features), "\n")
cat("Number of features retained:", length(selected_features), "\n")

# Apply on training and test dataset
train_X <- train_X[, selected_features]
test_X <- test_X[, selected_features]
```

sqrt(31,269) still leaves \~173 features to be considered at each split. We will try if the model works for a lower number of features, with the aim to increase interpretability of the final model. Thus we define our grid for the hyperparameter m as follows:

```{r}
# Define the hyperparameter grid for tuning
tune_grid <- expand.grid(
  mtry = c(100, 150)
)
```

We will use the balanced accuracy as our performance metric as the dataset is highly imbalanced.

```{r}
calculate_balanced_accuracy <- function(data, lev = NULL, model = NULL) {
  # Ensure levels are properly defined
  if (is.null(lev)) stop("Levels (lev) must be provided.")
  
  # Create confusion matrix
  confusion_matrix <- table(data$obs, data$pred, dnn = c("Observed", "Predicted"))
  
  # Ensure confusion matrix is correctly sized
  if (nrow(confusion_matrix) < 2 || ncol(confusion_matrix) < 2) {
    return(c(BalancedAccuracy = NA))
  }
  
  # Extract counts
  TP <- confusion_matrix[lev[1], lev[1]]
  FN <- confusion_matrix[lev[2], lev[1]]
  TN <- confusion_matrix[lev[2], lev[2]]
  FP <- confusion_matrix[lev[1], lev[2]]
  
  # Calculate sensitivity and specificity
  sensitivity <- ifelse((TP + FN) > 0, TP / (TP + FN), NA)
  specificity <- ifelse((TN + FP) > 0, TN / (TN + FP), NA)
  
  # Calculate balanced accuracy
  balanced_acc <- mean(c(sensitivity, specificity), na.rm = TRUE)
  
  return(c(BalancedAccuracy = balanced_acc))
}
```

Again, we calculate weights to account for the high imbalance of our dataset.

```{r}
# Assign weights to classes
class_weights <- ifelse(train2_data$label == 1, nrow(train2_data)/ (2*sum(train2_data$label==1)), nrow(train2_data)/ (2*sum(train2_data$label==-1)))
```

We are using a 5-fold Cross-validation to find the optimal split nodes and values.

```{r}
# Set up cross-validation
control <- trainControl(
  method = "cv",
  number = 5, 
  verboseIter = TRUE,
  savePredictions = "final",
  summaryFunction = calculate_balanced_accuracy
)
```

We are training the model on our training dataset that only contains the selected features (variance \> 0.01). We are also evaluating different values for the number of trees and the nodesize in our random forest.

```{r}
# Ensure that the label is stored as a factor
train_Y <- factor(train_Y, levels = c(0, 1), labels = c("Class0", "Class1"))
test_Y <- factor(test_Y, levels = c(0, 1), labels = c("Class0", "Class1"))

#RF_train <- data.frame(train_X, label = train_Y)

# Define values to test for ntree and nodesize
ntree_values <- seq(10, 15, 20)
nodesize_values <- c(8, 10, 12)

# Initialize variables to track the best model
best_model <- NULL
best_balanced_accuracy <- 0

# Enable parallel processing
cl <- makeCluster(detectCores() - 1)  # Use all available cores except one
registerDoParallel(cl)

# Loop over combinations of ntree and nodesize
for (ntree in ntree_values) {
  for (nodesize in nodesize_values) {
    set.seed(123)
    
    # Train the model for each combination
    rf_tuned_model <- train(
      x = train_X,
      y = train_Y,
      method = "rf",
      metric = "BalancedAccuracy",
      weights = class_weights,
      tuneGrid = tune_grid,  
      trControl = control,
      ntree = ntree,
      nodesize = nodesize,
      importance = TRUE
    )
    
    # Check performance on validation
    best_index <- which.max(rf_tuned_model$results$BalancedAccuracy)
    current_balanced_accuracy <-rf_tuned_model$results$BalancedAccuracy[best_index]
    
    # Update the best model if current is better
    if (current_balanced_accuracy > best_balanced_accuracy) {
      best_balanced_accuracy <- current_balanced_accuracy
      best_model <- rf_tuned_model
    }
  }
}

stopCluster(cl)

# Print the best model and performance
print(best_model)
```

The best model has the following combinations of parameter values:

-   mtry = 100

-   ntree = 10

-   nodesize = 10

In random forest, the number of selected features refers to the features that were used in splitting at least one node in the tree. In the following, we will extract the selected features using the importance score that has been assigned to them during the model training.

```{r}
# Extract final model
final_model <- best_model$finalModel

# Use the randomForest importance function
feature_importance <- randomForest::importance(final_model)

# Get features with non-zero importance
selected_features <- rownames(feature_importance)[apply(feature_importance, 1, function(x) any(x > 0))]

# Print selected features
print(length(selected_features))
```

We can see that 197 features have been selected. Now we fit our model on the subset of selected features.

```{r}
# Retrain model on the subset of data with only the selected features 
reduced_train_X <- train2_data[, selected_features]
reduced_test_X <- test2_data[, selected_features]
```

```{r}
# Set seed for reproducibility and comparison with other models
set.seed(123)

# Train best random forest model on the parameters of the final model
rf_final_model <- randomForest(
  x = reduced_train_X,
  y = train_Y,
  ntree = 10,
  mtry = 100, 
  nodesize = 10
)
```

We now evaluate the final model on the unseen test data and extract the balanced accuracy.

```{r}
# Predicting on test set
rf_predictions <- predict(rf_final_model, newdata = test_X)

# Confusion matrix
conf_matrix_rf <- confusionMatrix(rf_predictions, test_Y)

# Display confusion matrix
print(conf_matrix_rf)
```

The balanced accuracy on the testing set is 0.7187.

## Extreme Gradient Boosting (XGBoost)

XGBoost is a gradient boosting algorithm that builds an ensemble of decision trees to optimize predictive accuracy while providing feature importance scores. We chose it as we believe that its scalability and ability to handle high-dimensional data, as well as its speed make it a powerful tool for feature selection.

At first we create the training and testing set.

```{r}
# Random split (80% training, 20% testing)
set.seed(123)
train_indices <- sample(1:nrow(MLData_Task2), size = 0.8 * nrow(MLData_Task2))

# Create training and testing datasets
train2_data <- MLData_Task2[train_indices, ]
test2_data <- MLData_Task2[-train_indices, ]

# Ensure labels are 0 and 1 and stored as numeric vector for XGBoost
train2_data$label <- ifelse(train2_data$label == -1, 0, 1)
test2_data$label <- ifelse(test2_data$label == -1, 0, 1)

# Prepare data for XGBoost
train_matrix <- xgb.DMatrix(data = as.matrix(train2_data[,-1]), label = train2_data$label)
test_matrix <- xgb.DMatrix(data = as.matrix(test2_data[,-1]), label = test2_data$label)
```

We write our function to calculate the balanced accuracy during model fitting and evaluation.

```{r}
balanced_accuracy <- function(preds, dtrain) {
  # Get true labels
  labels <- getinfo(dtrain, "label")
  
  # Convert predicted probabilities to binary classes (threshold = 0.5)
  predictions <- ifelse(preds > 0.5, 1, 0)
  
  # Confusion matrix components
  TP <- sum(predictions == 1 & labels == 1)
  TN <- sum(predictions == 0 & labels == 0)
  FP <- sum(predictions == 1 & labels == 0)
  FN <- sum(predictions == 0 & labels == 1)
  
  # Sensitivity and Specificity
  sensitivity <- TP / (TP + FN)
  specificity <- TN / (TN + FP)
  
  # Balanced Accuracy
  balanced_acc <- (sensitivity + specificity) / 2
  
  # Return metric as a list
  return(list(metric = "BalancedAccuracy", value = balanced_acc))
}
```

Next, we define our gridsearch for the hyperparameter tuning. XGBoost has a lot of different parameters that need to be controlled to optimize the model, which can be separated into three types:

-   **General Parameters:** Define which booster to use, e.g., a tree or a linear model. We will use the default, which is a tree model.

-   **Booster Parameters (tree-specific)**:

    -   **eta**: Specifies the step size shrinkage for the feature weights used in the next iteration of the boosting algorithm. The default is set to 0.3, so we will try one more and one less conservative value to see if it improves performance.

    -   **max_depth**: Specifies the maximum depth of a tree. The default is set to 6, we will try lower and higher values as well.

    -   **colsample_bytree**: Specifies the subsample of columns when constructing each tree. The default is 1, we will try a lower value as well.

-   **Task Parameters**

    -   **base_score**: We will use the default of 0.5

    -   **objective**: Specifies the type of learner. As we have a classification task, we will use logistic regression.

    -   **eval_metric**: Specifies the evaluation metric for validation data. We will use the balanced accuracy, as always.

    -   **seed**: Specifies the seed to reproduce the same set of outputs.

Now we run the cross validation and grid search to identify the best set from the above described booster parameters.

```{r}
# Calculate scale_pos_weight to pass classweights to XGBoost
num_negative <- sum(train2_data$label == 0)
num_positive <- sum(train2_data$label == 1)
scale_pos_weight <- num_negative / num_positive
```

```{r}
# Grid search for hyperparameter tuning
search_grid <- expand.grid(
  max_depth = c(2, 4, 6, 8),
  eta = c(0.01, 0.05, 0.07, 0.1),
  colsample_bytree = c(0.7, 1.0)
)

# Initialize variables to track the best model
best_balanced_acc <- 0
best_params <- list()

# Enable parallel processing
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)

# Perform grid search
for (i in 1:nrow(search_grid)) {
  params <- list(
    objective = "binary:logistic",
    max_depth = search_grid$max_depth[i],
    eta = search_grid$eta[i],
    colsample_bytree = search_grid$colsample_bytree[i],
    scale_pos_weight = scale_pos_weight
  )
  
  # Perform cross-validation
  set.seed(123)
  cv_results <- xgb.cv(
    params = params,
    data = train_matrix,
    nfold = 5,
    nrounds = 500,
    early_stopping_rounds = 50,
    feval = balanced_accuracy,
    maximize = TRUE,
    verbose = FALSE
  )
  
  # Extract the best Balanced Accuracy
  mean_balanced_acc <- max(cv_results$evaluation_log$test_BalancedAccuracy_mean)
  
  # Update the best model parameters if current model is better
  if (mean_balanced_acc > best_balanced_acc) {
    best_balanced_acc <- mean_balanced_acc
    best_params <- params
    best_nrounds <- cv_results$best_iteration
  }
}

stopCluster(cl)
```

```{r}
# Set seed for reproducibility and comparison with other models
set.seed(123)
# Train final model with optimal hyperparameters
final_model <- xgb.train(
  params = best_params,
  data = train_matrix,
  nrounds = best_nrounds
)
```

```{r}
# Print the results
print(best_params)
cat("Best Balanced Accuracy:", best_balanced_acc, "\n")
cat("Best number of rounds:", best_nrounds, "\n")

# Get feature importance from the final model
importance <- xgb.importance(model = final_model)

# Number of features selected (importance score > 0)
selected_features <- nrow(importance)
cat("Number of selected features:", selected_features, "\n")

# Count the number of features with non-zero importance
non_zero_features <- sum(importance$Gain > 0)
cat("Number of features with non-zero importance:", non_zero_features, "\n")
```

The best model has the following parameter values:

-   max_depth - 4 ,

-   eta - 0.1 ,

-   colsample_bytree - 1 .

The best model selects 42 out of the 100,000 features and returns a balanced accuracy of \~0.81 on the training set. As our objective to binary:logistic does not directly predict classes, but rather probabilities, we need to convert the probabilities into our classes.

```{r}
set.seed(123)
# Use the best model to predict on the test set
xgb_predictions <- predict(final_model, newdata = test_matrix)

# Convert predictions at threshold
binary_predictions <- ifelse(xgb_predictions > 0.5, 1, 0)

# Convert binary predictions to a factor
binary_predictions <- factor(binary_predictions, levels = c(0, 1))

# Convert true labels to a factor with the same levels
true_labels <- factor(test2_data$label, levels = c(0, 1))
```

```{r}
# Store confusion matrix
conf_matrix <- confusionMatrix(binary_predictions, true_labels)

# Print the confusion matrix and balanced accuracy
print(conf_matrix)
```

Our final XGBoost model returns a balanced accuracy of 0.715 on the test data set.

## Elastic Net

Elastic Net is a regularized regression method that combines the strengths of Lasso (L1 regularization) and Ridge (L2 regularization). It is particularly useful for high-dimensional datasets where the number of features exceeds the number of observations or when features are highly correlated. Elastic Net introduces two hyperparameters: alpha, which controls the balance between Lasso and Ridge penalties, and lambda, which determines the overall strength of regularization. By shrinking less important coefficients towards zero and selecting only the most relevant features, Elastic Net reduces model complexity and enhances predictive performance. This makes it a powerful tool for feature selection and classification tasks in challenging datasets.

```{r}
# Split dataset into train and test set 
set.seed(123)
train_indices <- sample(1:nrow(MLData_Task2), size = 0.8 * nrow(MLData_Task2))
train_data <- MLData_Task2[train_indices, ]
test_data <- MLData_Task2[-train_indices, ]
```

```{r}
# Store features and labels separately
train_X <- as.matrix(train_data[, -1])  
test_X <- as.matrix(test_data[, -1])    
train_Y <- factor(train_data$label, levels = c(-1, 1), labels = c(0, 1))  
test_Y <- factor(test_data$label, levels = c(-1, 1), labels = c(0, 1))    
```

As we encounter stackoverflow issues when fitting the model on a larger set of features, we perform a pre-selection of features over the variance threshold of 0.05. A reason for the error could be, that with a higher number of features, issues such as multicollinearity and insufficient penalization can arise, causing numerical instability in Elastic Net.

```{r}
feature_variances <- apply(train_X, 2, var)
selected_features <- which(feature_variances >= 0.05)  
train_X <- train_X[, selected_features]
test_X <- test_X[, selected_features]

cat("Number of features after variance filtering:", ncol(train_X), "\n")
```

The threshold 0.05 reduces dimensions to \~1,194 features, balancing computational feasibility and information retention.

```{r}
# Scale data
train_X <- scale(train_X)
test_X <- scale(test_X)
```

Standardizes features to have zero mean and unit variance, critical for regularization-based methods like Elastic Net, which are sensitive to feature scales.

```{r}
# Calculate class weights to account for imbalance in dataset
class_weights <- ifelse(train_data$label == 1, nrow(train_data)/ (2*sum(train_data$label==1)), nrow(train_data)/ (2*sum(train_data$label==-1)))
```

```{r}
# Define custom balanced accuracy function
calculate_balanced_accuracy <- function(data, lev = NULL, model = NULL) {
  confusion_matrix <- table(data$obs, data$pred)
  if (nrow(confusion_matrix) < 2 || ncol(confusion_matrix) < 2) {
    sensitivity <- 0
    specificity <- 0
  } else {
    TP <- confusion_matrix[1, 1]
    FN <- confusion_matrix[2, 1]
    TN <- confusion_matrix[2, 2]
    FP <- confusion_matrix[1, 2]
    sensitivity <- TP / (TP + FN)
    specificity <- TN / (TN + FP)
  }
  balanced_acc <- (sensitivity + specificity) / 2
  return(c(BalancedAccuracy = balanced_acc))
}
```

```{r}
# Set up traincontrol environment
train_control <- trainControl(
  method = "cv",
  number = 5,
  summaryFunction = calculate_balanced_accuracy,
  savePredictions = "final",
  verboseIter = TRUE
)
```

We use a 5-fold cross-validation for training.

```{r}
# Specify hyperparameter grid
elastic_net_grid <- expand.grid(
  alpha = seq(0, 1, by = 0.2),  
  lambda = 10^seq(-4, -2, length.out = 10)  
)
```

Defines a grid of hyperparameters for Elastic Net: - alpha: Controls the balance between L1 (sparse selection) and L2 (shrinkage) penalties. - lambda: Regularization strength.

```{r}
# Enable parallel processing
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)

# Train Elastic Net model
set.seed(123)
elastic_net_model <- train(
  x = train_X,
  y = train_Y,
  method = "glmnet",
  metric = "BalancedAccuracy",
  trControl = train_control,
  tuneGrid = elastic_net_grid,
  weights = class_weights
)

# Stop the cluster after training
stopCluster(cl)

# Print the best parameters
print(elastic_net_model$bestTune)
```

We train the Elastic Net model using the defined hyperparameter grid and class weights while applying parallel processing to reduce computational time.

```{r}
# Extract best parameters 
best_lambda <- elastic_net_model$bestTune$lambda

# Extract coefficients for the best lambda
coefficients <- coef(elastic_net_model$finalModel, s = best_lambda)

# Count non-zero coefficients (excluding the intercept)
non_zero_count <- sum(coefficients != 0) - 1
cat("Number of non-zero coefficients:", non_zero_count, "\n")
```

```{r}
set.seed(123)
# Make predictions on test dataset
elastic_predictions <- predict(elastic_net_model, test_X)

# Generate confusion matrix
conf_matrix <- confusionMatrix(elastic_predictions, test_Y)

# Print confusion matrix and metrics
print(conf_matrix)
```

The model achieves a balanced accuracy of 0.71 on the test set, indicating good overall performance on this imbalanced dataset. The sensitivity (97.89%) is high, showing the model is effective at identifying the majority class. However, specificity (44.44%) is lower, reflecting challenges in correctly classifying the minority class.

Using a variance threshold of 0.05 reduced the features to 1,194, enabling significant dimensionality reduction. Lower thresholds (e.g., 0.01 or 0.02) resulted in NaN balanced accuracy, demonstrating the trade-off between stability and the number of features selected.

## SVM with RFE

RFE (Recursive Feature Elimination) is a feature selection technique that iteratively builds models, removes the least important features, and re-trains the model. Support Vector Machines is an effective classifier in high dimensions and it reduces the risk of overfitting. Together SVM and RFE retains high classification performance by focusing on the most discriminative features while improving the model efficiency.

```{r}
# Random split (80% training, 20% testing)
set.seed(123)
train_indices <- sample(1:nrow(MLData_Task2), size = 0.8 * nrow(MLData_Task2))

# Create training and testing datasets
train2_data <- MLData_Task2[train_indices, ]
test2_data <- MLData_Task2[-train_indices, ]

# Prepare data
train_X <- as.matrix(train2_data[, -1])
test_X <- as.matrix(test2_data[, -1])
train_Y <- factor(train2_data$label, levels = c(-1, 1), labels = c(0, 1))
test_Y <- factor(test2_data$label, levels = c(-1, 1), labels = c(0, 1))

# Verify split
cat("Training set size:", nrow(train2_data), "\n")
cat("Test set size:", nrow(test2_data), "\n")
```

Applying a pre-selection of features by removing those features with a variance below 0.01 - given the low variance, these features will likely not serve as good predictors for our classification task.

```{r}
# Calculate the variance of each feature
SVMfeature_variances <- apply(train_X, 2, var)

# Identify features with variance >= 0.01
SVMselected_features <- which(SVMfeature_variances >= 0.01)

# Print the number of features removed
cat("Number of features removed:", ncol(train_X) - length(SVMselected_features), "\n")
cat("Number of features retained:", length(SVMselected_features), "\n")

# Apply on training and test dataset
SVMtrain_X <- train_X[, SVMselected_features]
SVMtest_X <- test_X[, SVMselected_features]
```

Standardize the features by centering (subtracting the mean) and scaling (dividing by the standard deviation). Standardization is important for SVM because it ensures that all features are on the same scale, preventing features with larger magnitudes from dominating the SVM's decision boundary. Centering (subtracting the mean) ensures that each feature has a mean of zero, which helps improve the optimization process and convergence of the SVM algorithm.

```{r}
# Standardize the features by centering and scaling 
preProcValues <- preProcess(SVMtrain_X, method = c("center", "scale"))
SVMtrain_X <- predict(preProcValues, SVMtrain_X)
SVMtest_X <- predict(preProcValues, SVMtest_X)
```

Set up training control for Recursive Feature Elimination (RFE) with cross-validation. The rfeControl function specifies the method of resampling (cross-validation) and the number of folds (10). Then, run RFE using a SVM with a linear kernel. The rfe function evaluates different subsets of features (sizes 10, 20, 30, 40, 50, 60, 70, 80, 90, 100) to determine the optimal number of features based on model performance. Cross-validation is used to estimate the performance of each feature subset.

```{r}
# Set up training control with cross-validation
ctrl <- rfeControl(functions=rfFuncs, method="cv", number=10)

# Run RFE with SVM model with different sizes to determine the best number of features
svm_rfe <- rfe(SVMtrain_X, train_Y, sizes=c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100), 
               rfeControl=ctrl, method="svmLinear")
print(svm_rfe)
```

Size 30 was selected because it has the highest accuracy at 0.9391.

The svm_rfe object contains the result of the RFE process, including the set of features that resulted in the best model performance. Then, subset the training and test data to include only the selected features. This ensures that the model is trained and evaluated only on the most relevant features.

```{r}
# Getting the optimal subset of features based on RFE
selected_features <- svm_rfe$optVariables
print(selected_features)

# Subset the training and test data to include only the selected features
X_train_selected <- SVMtrain_X[, selected_features]
X_test_selected <- SVMtest_X[, selected_features]

```

Printed out above are the 30 features that were selected.

Defined a tuning grid to find the optimal value of C. Train the linear SVM model using the selected features from above.
```{r}
tune_grid <- expand.grid(C = c(0.01, 0.1, 1, 10, 100))
tuned_svm <- train(
  X_train_selected, 
  as.factor(train_Y), 
  method = "svmLinear",
  tuneGrid = tune_grid,
  trControl = trainControl(method = "cv", number = 10),
  metric = "Accuracy"
)

print(tuned_svm)
```
The optimal cost is C = 1

After training the model, the 'predict' function is used to generate predictions (y_pred) for the test set based on the features (X_test_selected) that were selected during feature selection.
```{r}
# Generate predictions on the test set using the trained SVM model
y_pred <- predict(tuned_svm, X_test_selected)

# Ensure y_pred and test_Y are factors with the same levels
y_pred <- factor(y_pred, levels = levels(test_Y)) 
test_Y <- factor(test_Y, levels = levels(y_pred))  
```

Generate the confusion matrix to evaluate the performance of the model and extract the Balanced Accuracy from the confusion matrix results.
```{r}
# Evaluate the model using balanced accuracy
conf_matrix <- confusionMatrix(y_pred, test_Y)
print(conf_matrix)
balanced_accuracy <- conf_matrix$byClass["Balanced Accuracy"]
print(paste("SVM with RFE Balanced Accuracy: ", balanced_accuracy))
```

SVM with RFE Balanced Accuracy: 0.73943661971831

## Gradient Boosting

Gradient Boosting is a technique that builds models sequentially by combining multiple weak learners, in this case decision trees, to create a strong predictive model. Each tree corrects the errors of the previous one by focusing on minimizing a specific loss function using gradient descent. GB improves predictions by fitting new models to the residuals of the previous models, making it a worthy candidate for our classification task.

```{r}
# Set seed for reproducibility
set.seed(123)

#Splitting data into training and testing sets (80-20 split)
train_indices <- sample(1:nrow(MLData_Task2), size = 0.8 * nrow(MLData_Task2))
GBtrain_data <- MLData_Task2[train_indices, ]
GBtest_data <- MLData_Task2[-train_indices, ]

# Ensure labels are factors with two levels for classification
GBtrain_data$label <- factor(GBtrain_data$label, levels = c(-1, 1), labels = c("Class1", "Class2"))
GBtest_data$label <- factor(GBtest_data$label, levels = c(-1, 1), labels = c("Class1", "Class2"))
```

We apply a pre-selection of features by dropping those with a variance \< 0.05 as we otherwise encounter a stackoverflow problem.

```{r}
# Calculating variance of numeric features
variance_threshold <- 0.05  
feature_variances <- apply(GBtrain_data[,-1], 2, var, na.rm = TRUE)  

# Select features with variance above the threshold
selected_features <- names(feature_variances[feature_variances > variance_threshold])
cat("Number of features retained after variance threshold:", length(selected_features), "\n")
```

We can see that 1194 features have been selected. Now we will fit our model on the subset of selected features.

```{r}
selected_features <- intersect(selected_features, colnames(GBtrain_data))
# Create training and testing sets
GB_train_X <- GBtrain_data[, selected_features]
GB_test_X <- GBtest_data[, selected_features]
GB_train_Y <- GBtrain_data$label
GB_test_Y <- GBtest_data$label
```

We specify the function to calculate the balanced accuracy.

```{r}
# Set up balanced accuracy function
calculate_balanced_accuracy <- function(data, lev = NULL, model = NULL) {
  confusion_matrix <- table(data$obs, data$pred)
  
  if (nrow(confusion_matrix) < 2 || ncol(confusion_matrix) < 2) {
    return(c(BalancedAccuracy = 0))
  }
  
  TP <- confusion_matrix[2, 2]
  FN <- confusion_matrix[2, 1]
  TN <- confusion_matrix[1, 1]
  FP <- confusion_matrix[1, 2]
  
  sensitivity <- TP / (TP + FN)
  specificity <- TN / (TN + FP)
  balanced_acc <- (sensitivity + specificity) / 2
  
  return(c(BalancedAccuracy = balanced_acc))
}
```

We set our traincontrol function up for a 5-fold CV.

```{r}
# Set up traincontrol
GBtrain_control <- trainControl(
  method = "cv",                    
  number = 5,                       
  summaryFunction = calculate_balanced_accuracy, 
  classProbs = TRUE                
)
```

We now define a grid of hyperparameter combinations for tuning the Model. It specifies various values for key parameters: learning rate, number of trees, maximum tree depth minimum observations required in a terminal node. We are aiming for a comprehensive set of parameter combinations to optimize the model's performance during training.

```{r}
# Define hyperparametergrid for tuning
GBtune_grid <- expand.grid(
 shrinkage = c(0.001, 0.01, 0.03, 0.05, 0.1, 0.2),  
  n.trees = c(10, 20, 50),     
  interaction.depth = c(1, 3, 5),         
  n.minobsinnode = c(5, 10, 15)           
)
```

```{r}
# Assign class weights to account for the imbalance of the dataset
class_weights <- ifelse(GB_train_Y == "Class2", 
                        1 / sum(GB_train_Y == "Class2"), 
                        1 / sum(GB_train_Y == "Class1"))
```

```{r}
# Create dataframe for training the GB model
GB_train <- data.frame(GB_train_X, label = GB_train_Y)

# Set seed for reproducibility
set.seed(123)

# Train the GBM model
gbm_model <- train(
  label ~ .,
  data = GB_train,
  method = "gbm",
  weights = class_weights,
  trControl = GBtrain_control,
  tuneGrid = GBtune_grid,
  metric = "BalancedAccuracy",
  verbose = FALSE
)

# Printing the best model parameters
cat("Best Model Parameters:\n")
print(gbm_model$bestTune)
```

Our CV selects the model with the following hyperparamters as our best model: n.trees = 20, interaction.depth = 3, shrinkage = 0.1 and n.miniobsinnode = 15.

```{r}
# Save best model
gbm_final_model <- gbm_model$finalModel
```

```{r}
# Extract feature importance
GBfeature_importance <- summary(gbm_final_model, plot = FALSE)

# Set a minimum importance threshold
importance_threshold <- 0

# Filter features based on the threshold
selected_features <- GBfeature_importance %>%
  filter(rel.inf > importance_threshold) %>%
  pull(var)

cat("Number of features selected based on importance threshold:", length(selected_features), "\n")
```

Our final model selected 36 features.

```{r}
# Predict class labels
gbm_predictions <- ifelse(
  predict(gbm_final_model, GB_test_X, n.trees = gbm_final_model$n.trees) > 0.5, 
  "Class1", 
  "Class2"
)

# Ensure predictions and test data have the same factor levels
gbm_predictions <- factor(gbm_predictions, levels = levels(GB_test_Y))

# Confusion Matrix
conf_matrix <- confusionMatrix(gbm_predictions, GB_test_Y)
print(conf_matrix)
```

As the confusion matrix shows, our model returns a balanced accuracy of 0.7152 on the test data.
